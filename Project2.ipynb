{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T14:48:55.533145Z",
     "iopub.status.busy": "2021-02-09T14:48:55.532569Z",
     "iopub.status.idle": "2021-02-09T14:48:56.354332Z",
     "shell.execute_reply": "2021-02-09T14:48:56.353423Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from group_lasso import GroupLasso\n",
    "from sklearn.utils import resample, check_random_state\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "from extra_functions import *\n",
    "\n",
    "# Silence some warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T14:48:56.358461Z",
     "iopub.status.busy": "2021-02-09T14:48:56.357998Z",
     "iopub.status.idle": "2021-02-09T14:49:04.818353Z",
     "shell.execute_reply": "2021-02-09T14:49:04.818809Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('energydata_complete.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.set_index('date')\n",
    "\n",
    "fig = plot_data(df)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating extra features to describe time\n",
    "weekday: number [0,6]\\\n",
    "weekstatus: binary describing weekend (1) or not (0)\\\n",
    "NSM: Number of Seconds from Midnight\n",
    "\n",
    "These are used for filtering the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T14:49:04.852017Z",
     "iopub.status.busy": "2021-02-09T14:49:04.851538Z",
     "iopub.status.idle": "2021-02-09T14:49:04.853614Z",
     "shell.execute_reply": "2021-02-09T14:49:04.854001Z"
    }
   },
   "outputs": [],
   "source": [
    "weekday = np.zeros(len(df))\n",
    "weekstatus = np.zeros(len(df))\n",
    "NSM = np.zeros(len(df))\n",
    "month = np.zeros(len(df))\n",
    "\n",
    "for i, val in enumerate(df.index):\n",
    "    weekday[i] = val.weekday()\n",
    "    weekstatus[i] = (weekday[i] >= 5)  # False for workday, True for weekend\n",
    "    NSM[i] = (val - val.replace(hour=0, minute=0, second=0, microsecond=0)).total_seconds()\n",
    "    month[i] = val.month\n",
    "\n",
    "df['weekday'] = weekday\n",
    "#df['week status'] = weekstatus\n",
    "df['NSM'] = NSM\n",
    "df['month'] = month\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add n previous timepoints to the data\n",
    "\n",
    "Here we add the result vector from \"t-n\" as part of the covariates. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [1, 10, 100] # Make a list in-case we want to skip some \"n\"\n",
    "y = df['Appliances'].values # get y\n",
    "for n in ns:\n",
    "    temp = np.zeros_like(y)\n",
    "    temp[n:] = y[:-n]\n",
    "    df[f\"t-{n}\"]=temp\n",
    "# Strip the first max(n) datapoints that now miss data\n",
    "n = max(ns)\n",
    "df = df[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T14:49:04.860842Z",
     "iopub.status.busy": "2021-02-09T14:49:04.859591Z",
     "iopub.status.idle": "2021-02-09T14:49:04.988072Z",
     "shell.execute_reply": "2021-02-09T14:49:04.987599Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "# These two plots should be identical\n",
    "plt.plot(df['t-1'][:10],df['Appliances'][:10], lw=3, label=\"real\")\n",
    "plt.plot(df['t-1'][:10], df['t-1'][1:11], label=\"shifted t-1\") \n",
    "plt.xlabel('t-1')\n",
    "plt.ylabel('Appliances')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering data and making training/validation/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T14:49:04.992536Z",
     "iopub.status.busy": "2021-02-09T14:49:04.992044Z",
     "iopub.status.idle": "2021-02-09T14:49:04.997415Z",
     "shell.execute_reply": "2021-02-09T14:49:04.997822Z"
    }
   },
   "outputs": [],
   "source": [
    "indices = (np.in1d(df.index.month, (1,2)))\n",
    "\n",
    "#standardization\n",
    "\n",
    "#y = np.array(df_train['Appliances']).reshape(-1,1)\n",
    "#X = np.array(df_train[df_train.columns[1:]])\n",
    "#X, y = standardize(X,y)\n",
    "\n",
    "# Train/validation/test\n",
    "\n",
    "df_train = df[indices]\n",
    "df_valid = df[(df.index.month==3)]\n",
    "df_test = df[(df.index.month==4)]\n",
    "\n",
    "X_train = np.array(df_train[df.columns[df.columns!='Appliances']])\n",
    "y_train = np.array(df_train[df.columns[df.columns=='Appliances']])\n",
    "X_test = np.array(df_test[df.columns[df.columns!='Appliances']])\n",
    "y_test = np.array(df_test[df.columns[df.columns=='Appliances']])\n",
    "X_valid = np.array(df_valid[df.columns[df.columns!='Appliances']])\n",
    "y_valid = np.array(df_valid[df.columns[df.columns=='Appliances']])\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "scaler = StandardScaler().fit(X_valid)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "scaler = StandardScaler().fit(X_test)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_test_mean = y_test.mean()\n",
    "y_valid_mean = y_valid.mean()\n",
    "y_train_mean = y_train.mean()\n",
    "\n",
    "y_train = y_train - y_train_mean\n",
    "y_valid = y_valid - y_valid_mean\n",
    "y_test = y_test - y_test_mean\n",
    "\n",
    "#X_train, y_train = standardize(X_train,y_train)\n",
    "#X_valid, y_valid = standardize(X_valid,y_valid)\n",
    "#X_test, y_test = standardize(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the filter was correct\n",
    "print(len(df[(df.index.month==1)])+ len(df[(df.index.month==2)]))\n",
    "print(len(df_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations of covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T14:49:05.005598Z",
     "iopub.status.busy": "2021-02-09T14:49:05.001748Z",
     "iopub.status.idle": "2021-02-09T14:49:05.614325Z",
     "shell.execute_reply": "2021-02-09T14:49:05.613576Z"
    }
   },
   "outputs": [],
   "source": [
    "cor = df_train[df_train.columns].corr()\n",
    "fig, ax = plt.subplots(figsize=(10,10)) \n",
    "sns.heatmap(cor, square=True, xticklabels=True, yticklabels=True, cmap='RdBu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "\n",
    "### Feedforward Neural Network\n",
    "The first neural network is actually not a RNN, but a feedforward network, where we include the input features t-n, which denotes the response variable from earlier time steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T14:49:06.413613Z",
     "iopub.status.busy": "2021-02-09T14:49:06.413094Z",
     "iopub.status.idle": "2021-02-09T14:49:08.797491Z",
     "shell.execute_reply": "2021-02-09T14:49:08.796705Z"
    }
   },
   "outputs": [],
   "source": [
    "# Martins code here\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Input, regularizers\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU, SimpleRNN\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "## A feedforward neural network with one hidden layer is made. A ReLU activation is used in the hidden layer.\n",
    "## An output layer with a single output node is used\n",
    "\n",
    "# Number of neurons in hidden layer:\n",
    "n_neurons = 10\n",
    "\n",
    "# L2 regularization \"lambda\"\n",
    "lmbda = 0\n",
    "\n",
    "# Early stopping\n",
    "es = EarlyStopping(monitor=\"val_loss\",patience=5)\n",
    "\n",
    "# NN\n",
    "nn = Sequential()\n",
    "nn.add(Dense(n_neurons, \n",
    "             activation='relu', \n",
    "             name=\"Dense1\",\n",
    "             kernel_regularizer=regularizers.l2(lmbda),\n",
    "             bias_regularizer=regularizers.l2(lmbda)           \n",
    "            )\n",
    "      )\n",
    "nn.add(Dense(1,activation='linear', name=\"outputlayer\"))\n",
    "\n",
    "# ADAM optimizer, learning rate and decay is specified\n",
    "opt = tf.keras.optimizers.Adam(lr=1e-3,decay=1e-5)\n",
    "\n",
    "# The NN is compiled. A MSE loss function is used.\n",
    "nn.compile(loss='mse',\n",
    "           optimizer=opt,\n",
    "           metrics='mse',\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model is fitted to the training data and validated using the validation data. Variable number of epochs.\n",
    "history = nn.fit(X_train,y_train, epochs=50, verbose=0, validation_data=(X_valid,y_valid),callbacks=es)\n",
    "\n",
    "# The predicted values are found using the test data\n",
    "y_pred = nn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(1,len(history.history['mse'])+1),history.history['mse'],'k-',label='Train')\n",
    "plt.plot(np.arange(1,len(history.history['mse'])+1),history.history['val_mse'],'b-',label='Validation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean squared error')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A summary of the used network\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that calculates the R^2 value\n",
    "def coeff_determination(y_true, y_pred):\n",
    "    SS_res =  np.sum(( y_true - y_pred )**2)\n",
    "    SS_tot = np.sum(( y_true - np.mean(y_true) )**2 )\n",
    "    return ( 1 - SS_res/SS_tot )\n",
    "\n",
    "# Train and test score given by R^2\n",
    "print('Train score: '+ str(coeff_determination(y_train,nn.predict(X_train))))\n",
    "print('Test score: '+ str(coeff_determination(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A plot of real data and predicted data in time between two time intervals:\n",
    "\n",
    "index_first = 1000\n",
    "index_last = 1500\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(df_test.index[index_first:index_last],y_test[index_first:index_last]+y_test_mean,'k-', label='True')\n",
    "plt.plot(df_test.index[index_first:index_last],y_pred[index_first:index_last]+y_test_mean,'r-', label='Predicted')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Appliances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(y_pred,y_test,'b.')\n",
    "plt.plot([-100,900],[-100,900],'k-')\n",
    "plt.grid()\n",
    "plt.xlabel('Predicted Appliances')\n",
    "plt.ylabel('True Appliances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Neural Network\n",
    "\n",
    "In this approach, the last three columns of the input containing information of previous output values are removed. Instead a neural network with recurrent layers is used. These layers takes the hidden state of the last output and feeds to the next input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "def reshape_lstm(X):\n",
    "    X_reshaped = X.reshape(X.shape[0],1,X.shape[1])\n",
    "    return X_reshaped\n",
    "\n",
    "# Removing the last three columns containing t-n.\n",
    "X_train_lstm = reshape_lstm(X_train[:,:-3])\n",
    "X_test_lstm = reshape_lstm(X_test[:,:-3])\n",
    "X_valid_lstm = reshape_lstm(X_valid[:,:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping\n",
    "es = EarlyStopping(monitor=\"val_loss\",patience=3)\n",
    "\n",
    "# L2 regularization \"lambda\"\n",
    "lmbda = 1e-2\n",
    "\n",
    "# Model\n",
    "model = Sequential()\n",
    "model.add(LSTM(10,input_shape=(X_train_lstm.shape[1],X_train_lstm.shape[2]),\n",
    "               return_sequences=False,\n",
    "               activation='relu',\n",
    "               kernel_regularizer=regularizers.l2(lmbda),\n",
    "               bias_regularizer=regularizers.l2(lmbda)))\n",
    "# model.add(Dense(10,\n",
    "#                activation='relu',\n",
    "#                kernel_regularizer=regularizers.l2(lmbda),\n",
    "#                bias_regularizer=regularizers.l2(lmbda)))\n",
    "model.add(Dense(1,activation='linear', name=\"outputlayer\"))\n",
    "\n",
    "# ADAM optimizer, learning rate and decay is specified\n",
    "opt = tf.keras.optimizers.Adam(lr=1e-3,decay=1e-5)\n",
    "\n",
    "# The NN is compiled. A MSE loss function is used.\n",
    "model.compile(loss='mse',\n",
    "           optimizer=opt,\n",
    "           metrics='mse')\n",
    "          \n",
    "          \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_lstm, y_train, epochs=100, verbose=0, validation_data=(X_valid_lstm,y_valid), callbacks=es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_lstm)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(1,len(history.history['mse'])+1),history.history['mse'],'k-',label='Train')\n",
    "plt.plot(np.arange(1,len(history.history['mse'])+1),history.history['val_mse'],'b-',label='Validation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean squared error')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Train and test score given by R^2\n",
    "print('Train score: '+ str(coeff_determination(y_train,model.predict(X_train_lstm))))\n",
    "print('Test score: '+ str(coeff_determination(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A plot of real data and predicted data in time between two time intervals:\n",
    "index_first = 0\n",
    "index_last = 1100\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(df_test.index[index_first:index_last],y_test[index_first:index_last]+y_test_mean,'k-', label='True')\n",
    "plt.plot(df_test.index[index_first:index_last],y_pred[index_first:index_last]+y_test_mean,'r-', label='Predicted')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Appliances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(y_pred,y_test,'b.')\n",
    "plt.plot([-100,900],[-100,900],'k-')\n",
    "plt.grid()\n",
    "plt.xlabel('Predicted Appliances')\n",
    "plt.ylabel('True Appliances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T14:49:08.802743Z",
     "iopub.status.busy": "2021-02-09T14:49:08.802250Z",
     "iopub.status.idle": "2021-02-09T14:49:09.362496Z",
     "shell.execute_reply": "2021-02-09T14:49:09.361497Z"
    }
   },
   "outputs": [],
   "source": [
    "# Youngrong's code her\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "## A randomforest model is made. All the ranges of the parameters used for the model are specified.\n",
    "## Hyperparameters are tunned by gridsearchCV on validation data(Month==3)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Range of the gridsearch for RF hyperparameters\n",
    "param_grid = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "    'max_features': ['auto','sqrt'],\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5],\n",
    "    'min_samples_split': [2, 4,6,8,10, 12, 14, 16, 18, 20],\n",
    "    'n_estimators': np.arange(200, 3100, 200).tolist()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid,\n",
    "#                                cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# # Validation with the data to find the best set of hyperparameters\n",
    "# grid_search.fit(X_valid,y_valid.ravel())\n",
    "\n",
    "# # A summary of the chosen pararmeters\n",
    "# print(grid_search.best_params_)\n",
    "\n",
    "# # The model is fitted to the training data and validated using the validation data.\n",
    "# rf = model.set_params(**grid_search.best_params_)\n",
    "\n",
    "# rf.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator = model, param_distributions = param_grid, n_iter = 100, cv = 3, verbose=2, random_state=1, n_jobs = -1)\n",
    "\n",
    "# Validation with the data to find the best set of hyperparameters\n",
    "random_search.fit(X_valid,y_valid.ravel())\n",
    "\n",
    "# A summary of the chosen pararmeters\n",
    "print('Best parameter:' +str(random_search.best_params_))\n",
    "\n",
    "# The model is fitted to the training data and validated using the validation data.\n",
    "rf = model.set_params(**random_search.best_params_)\n",
    "\n",
    "rf.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "import pickle\n",
    "filename = 'RF_model.sav'\n",
    "\n",
    "# load the model from disk\n",
    "rf = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The predicted values are found using the test data\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print('Train score: '+ str(coeff_determination(y_train.ravel(),rf.predict(X_train))))\n",
    "print('Test score: '+ str(coeff_determination(y_test.ravel(),y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A plot of real data and predicted data in time between two time intervals:\n",
    "\n",
    "index_first = 500\n",
    "index_last = 1000\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(df_test.index[index_first:index_last],y_test[index_first:index_last],'k-', label='True')\n",
    "plt.plot(df_test.index[index_first:index_last],y_pred[index_first:index_last],'r-', label='Predicted')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Appliances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(y_pred,y_test,'b.')\n",
    "plt.plot([0,1000],[0,1000],'k-')\n",
    "plt.grid()\n",
    "plt.xlabel('Predicted Appliances')\n",
    "plt.ylabel('True Appliances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree surrogacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T14:49:10.115111Z",
     "iopub.status.busy": "2021-02-09T14:49:10.114442Z",
     "iopub.status.idle": "2021-02-09T14:49:10.117154Z",
     "shell.execute_reply": "2021-02-09T14:49:10.116723Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sander's code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
